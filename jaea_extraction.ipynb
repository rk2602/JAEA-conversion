{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# IMPORT ALL THE NECESSARY LIBRARIES\r\n",
    "#\r\n",
    "import math\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "from pathlib import Path\r\n",
    "from sklearn.metrics import r2_score\r\n",
    "import sys\r\n",
    "import os\r\n",
    "#\r\n",
    "# IDENTIFY THE DEFAULT PATH FOR ALL OUTPUT FILES (change the variable for path_1 to whatever your filepath is):\r\n",
    "#\r\n",
    "path_1 = Path(r'C:\\Users\\zavarin1\\Documents\\6. DRESDEN SMART KD CALCS\\jaea_online_extract')\r\n",
    "#path_1=Path(r'C:\\Users\\rk260\\OneDrive\\Desktop\\japan')\r\n",
    "#\r\n",
    "# Pull in datasets, tab delimited\r\n",
    "#\r\n",
    "df = pd.read_csv(path_1.joinpath(\"SDBDataDownload.txt\"),sep = '\\t',low_memory=False)\r\n",
    "#print(df.head(2))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Pull in dataset2, tab delimited\r\n",
    "#\r\n",
    "df1 = pd.read_csv(path_1.joinpath(\"SDBDataDownload-1.txt\"),sep = '\\t',low_memory=False)\r\n",
    "#print(df1.head(2))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Pull in dataset3, tab delimited\r\n",
    "#\r\n",
    "df2 = pd.read_csv(path_1.joinpath(\"SDBDataDownload-2.txt\"),sep = '\\t',low_memory=False)\r\n",
    "#print(df2.head(2))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Pull in dataset4, tab delimited\r\n",
    "#\r\n",
    "df3 = pd.read_csv(path_1.joinpath(\"SDBDataDownload-3.txt\"),sep = '\\t',low_memory=False)\r\n",
    "#print(df3.head(2))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "frames = [df, df1, df2, df3]\r\n",
    "#df4 = pd.concat(frames)\r\n",
    "#print(df4.head(2))\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "#Select subset of solid phase groups for further analysis and export csv file\r\n",
    "df5 = pd.concat(frames)\r\n",
    "acceptable=['Other minerals', 'Clay minerals', 'Bentonite (smectite)']\r\n",
    "indexNames = df5[ ~df5['Solid Phase Group'].isin(acceptable) ].index\r\n",
    "df5.drop(indexNames, inplace=True)\r\n",
    "#df5.to_csv('df5.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "#Export csv file of all atm/redox conditions in the jaea subset file\r\n",
    "atm_conditions = list(set(df5[\"atm/redox condition\"]))\r\n",
    "df10 = pd.DataFrame(atm_conditions)\r\n",
    "df10.to_csv(path_1.joinpath('atm_conditions.csv'), index = False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "#Rename the sorbent to LLNL SCIE format\r\n",
    "df5['redox'].replace({'I': '+1', 'II': '+2', 'III':'+3', 'IV':'+4', 'V':'+5' ,'VI':'+6', 'n.r':'n.r', 'VII':'+7', 'VIII':'+8', '-I':'-1','-II':'-2', 'V/IV': \"+5,4\", 'IV/V': \"+4,5\", 'V/VI': \"+5,6\"}, inplace=True)\r\n",
    "df5['Sorbent']=df5['Element']+'('+df5['redox'].astype(str)+')'\r\n",
    "df5['redox'].replace({'+1':'I', '+2':'II', '+3':'III', '+4':'IV', '+5':'V' ,'+6':'VI', 'n.r':'n.r', '+7':'VII', '+8':'VIII', '-1':'-I','-2':'-II', \"+5,4\":'V/IV',  \"+4,5\":'IV/V',  \"+5,6\":'V/VI'}, inplace=True)\r\n",
    "df5.drop('Element', inplace=True, axis=1)\r\n",
    "df5.drop('redox', inplace=True, axis=1)\r\n",
    "#df5.to_csv('df5.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "#Export csv of all jaea subset database minerals and Rename Solid Phase related columns\r\n",
    "df5.rename({'Solid Phase':'Mineral_sources'},axis=1,inplace=True)\r\n",
    "df7 = pd.read_csv(path_1.joinpath(\"minerals_conversion.csv\"))\r\n",
    "df7 = df7.reset_index().set_index('Mineral_source')\r\n",
    "df5['Mineral']=df5.apply(lambda row: df7.loc[row['Mineral_sources'],'Mineral'],axis=1)\r\n",
    "df5['Mineral_formula']=df5.apply(lambda row: df7.loc[row['Mineral_sources'],'Mineral_formula'],axis=1)\r\n",
    "df5.rename({'Mineral_sources':'Mineral_source'},axis=1,inplace=True)\r\n",
    "#df5.to_csv('df5.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "#Rename surface area information\r\n",
    "df5.rename({'Specific Surface Area(m2/g)':'MineralSA'},axis=1,inplace=True)\r\n",
    "df5['temporaire']=df5['MineralSA'].str.find(')')\r\n",
    "df5['MineralSA_SD']=df5.apply(lambda row: row['MineralSA'][row['temporaire']+1:] if row['temporaire']!=-1 else '',axis=1)\r\n",
    "df5['MineralSA_SD'].replace({'':'NA'},inplace=True)\r\n",
    "df5['temporaire']=df5['MineralSA'].str.find('(')\r\n",
    "df5['MineralSA']=df5.apply(lambda row: row['MineralSA'][:row['temporaire']] if row['temporaire']!=-1 else row['MineralSA'][:],axis=1)\r\n",
    "df5['MineralSA_units']='m2/g'\r\n",
    "df5.drop('temporaire', inplace=True, axis=1)\r\n",
    "#df5.to_csv('df5.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "#Rename CEC information\r\n",
    "df5.rename({'CEC(meq/100g)':'CEC'},axis=1,inplace=True)\r\n",
    "df5.replace({'':'NA','n.r.':'NA'},inplace=True)\r\n",
    "df5.fillna('NA',inplace=True)\r\n",
    "df5['CEC_SD']='NA'\r\n",
    "df5['CEC_units']='meq/100g'\r\n",
    "df5['temporaire']=df5['CEC'].str.find(')')\r\n",
    "df5['CEC_SD']=df5.apply(lambda row: row['CEC'][row['temporaire']+1:] if row['temporaire']!=-1 else '',axis=1)\r\n",
    "df5['CEC_SD'].replace({'':'NA'},inplace=True)\r\n",
    "df5['temporaire']=df5['CEC'].str.find('(')\r\n",
    "df5['CEC']=df5.apply(lambda row: row['CEC'][:row['temporaire']] if row['temporaire']!=-1 else row['CEC'][:],axis=1)\r\n",
    "df5['CEC_units']='meq/100g'\r\n",
    "df5.drop('temporaire', inplace=True, axis=1)\r\n",
    "#df5.to_csv('df5.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "#Remove unwanted columns\r\n",
    "df5.drop('note', inplace=True, axis=1)\r\n",
    "df5.drop('Solid Phase Group', inplace=True, axis=1)\r\n",
    "#df5.to_csv('df5.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "#Invert the solid solution value\r\n",
    "df5['Mineral_SD']='NA'\r\n",
    "df5['Mineral_units']='g/L'\r\n",
    "def initial_fxn (the_input):\r\n",
    "    if 'ca.' in the_input:\r\n",
    "        return float(the_input[3:])\r\n",
    "    elif '-' in the_input:\r\n",
    "        a=float(the_input[:the_input.index('-')])\r\n",
    "        b=float(the_input[the_input.index('-')+1:])\r\n",
    "        return (b-a)/2\r\n",
    "    else:\r\n",
    "        return 'NA'\r\n",
    "\r\n",
    "def the_fxn (my_input):\r\n",
    "    try:\r\n",
    "        return 1/float(my_input)*1000\r\n",
    "    except:\r\n",
    "        if 'ca.' in my_input:\r\n",
    "            return 1/float(my_input[3:])*1000\r\n",
    "        elif '-' in my_input:\r\n",
    "            a=float(my_input[:my_input.index('-')])\r\n",
    "            b=float(my_input[my_input.index('-')+1:])\r\n",
    "            c=a+((b-a)/2)\r\n",
    "            return 1/float(c)*1000\r\n",
    "        else:\r\n",
    "            return 'NA'\r\n",
    "\r\n",
    "df5['Mineral_SD']=df5.apply(lambda row: initial_fxn(row['Solution/Solid(mL/g)']),axis=1)\r\n",
    "df5['Solution/Solid(mL/g)']=df5.apply(lambda row: the_fxn(row['Solution/Solid(mL/g)']),axis=1)\r\n",
    "df5.rename({'Solution/Solid(mL/g)':'Mineral_val'},axis=1,inplace=True)\r\n",
    "#df5.to_csv('df5.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "#Export csv of all jaea subset database temperatures\r\n",
    "df5.drop('Solution(mL)', inplace=True, axis=1)\r\n",
    "df5.drop('Solid(g)', inplace=True, axis=1)\r\n",
    "#df5.to_csv('df5.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "#Rename temperature info\r\n",
    "def another_fxn(the_reference):\r\n",
    "    if '+' in the_reference and '-' in the_reference:\r\n",
    "        return float(the_reference[:the_reference.index('(')])\r\n",
    "    elif '-' in the_reference:\r\n",
    "        a=float(the_reference[:the_reference.index('-')])\r\n",
    "        b=float(the_reference[the_reference.index('-')+1:])\r\n",
    "        return float(a+b/2)\r\n",
    "    elif ',' in the_reference:\r\n",
    "        return 40\r\n",
    "    elif '?' in the_reference:\r\n",
    "        return float(the_reference[the_reference.index('?')-2:the_reference.index('?')])\r\n",
    "    else:\r\n",
    "        try:\r\n",
    "            return float(the_reference)\r\n",
    "        except:\r\n",
    "            try:\r\n",
    "                return float(the_reference[0:2])\r\n",
    "            except:\r\n",
    "                return 'NA'\r\n",
    "\r\n",
    "def final_fxn(other_reference):\r\n",
    "    if ')' in other_reference and 'room' not in other_reference:\r\n",
    "        try:\r\n",
    "            return float(other_reference[other_reference.index(')')+1:])\r\n",
    "        except:\r\n",
    "            return float(other_reference[-2])\r\n",
    "    elif '-' in other_reference:\r\n",
    "        a=float(other_reference[:other_reference.index('-')])\r\n",
    "        b=float(other_reference[other_reference.index('-')+1:])\r\n",
    "        return float(b-a/2)\r\n",
    "    elif ',' in other_reference:\r\n",
    "        return 20\r\n",
    "    elif '}' in other_reference:\r\n",
    "        return float(other_reference[other_reference.index('}')+1:other_reference.index('}')+2])\r\n",
    "    else:\r\n",
    "        try:\r\n",
    "            return float(other_reference[-1])\r\n",
    "        except:\r\n",
    "            return 'NA'\r\n",
    "\r\n",
    "df5['Temp']=df5.apply(lambda row: another_fxn(row['temp(degC)']),axis=1)\r\n",
    "df5['Temp_SD']=df5.apply(lambda row: final_fxn(row['temp(degC)']),axis=1)\r\n",
    "df5['Temp_SD'].replace({0:'NA', '0':'NA'},inplace=True)\r\n",
    "df5.drop('temp(degC)', inplace=True, axis=1)\r\n",
    "#df5.to_csv('df5.csv')"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "\r\n",
    "#Multistep conversion of electrolyte information\r\n",
    "reference=[('Na(ppm)','Na(+1)',22.99),('K(ppm)','K(+1)',39.1),('Ca(ppm)','Ca(+2)',40.08),('Mg(ppm)','Mg(+2)',24.31),('Cl(ppm)','Cl(-1)',35.45),('NO3(ppm)','N(+5)',62.01),('ClO4(ppm)','Cl(+7)',99.45),('HCO3(ppm)','C(+4)',61.02),('SO4(ppm)','S(+6)',96.06),('F(ppm)','F(-1)',19.0),('SiO2(ppm)','Si(+4)',60.09),('Fe(ppm)','Fe(+3)',55.84),('DOC(ppm)','DOC',12.01)]\r\n",
    "\r\n",
    "def a_fxn(a,b):\r\n",
    "    if a=='NA':\r\n",
    "        return 'NA'\r\n",
    "    else:\r\n",
    "        return b\r\n",
    "\r\n",
    "for f in range(1,len(reference)+1):\r\n",
    "    df5[\"Electrolyte\"+str(f)+\"_val\"]=df5.apply(lambda row: row[reference[f-1][0]]/reference[f-1][2]/1000 if row[reference[f-1][0]] != 'NA' else 'NA',axis=1)\r\n",
    "    df5[\"Electrolyte\"+str(f)]=reference[f-1][1]\r\n",
    "    df5[\"Electrolyte\"+str(f)+\"_SD\"]='NA'\r\n",
    "    df5[\"Electrolyte\"+str(f)+\"_units\"]='mol/L'\r\n",
    "    df5[\"Electrolyte\"+str(f)]=df5.apply(lambda row: a_fxn(row[\"Electrolyte\"+str(f)+\"_val\"], row[\"Electrolyte\"+str(f)]), axis=1)\r\n",
    "    df5[\"Electrolyte\"+str(f)+\"_units\"]=df5.apply(lambda row: a_fxn(row[\"Electrolyte\"+str(f)+\"_val\"], row[\"Electrolyte\"+str(f)+\"_units\"]), axis=1)\r\n",
    "    df5.drop(reference[f-1][0], inplace=True, axis=1)\r\n",
    "\r\n",
    "\r\n",
    "df5.fillna('NA',inplace=True)\r\n",
    "#df5.to_csv('df5.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "#Rename pH info and export csv with all pH values\r\n",
    "df5['pH']=df5.apply(lambda row: row['pH end'] if row['pH end'] != 'NA' else row['pH init'],axis=1)\r\n",
    "df5.drop('pH end', inplace=True, axis=1)\r\n",
    "df5['pH_SD']='NA'\r\n",
    "def pH_fxn(my_input):\r\n",
    "    if 'as' in my_input:\r\n",
    "        my_input=my_input[:-7]\r\n",
    "    if '(' in my_input:\r\n",
    "        return float(my_input[:my_input.index('(')])\r\n",
    "    elif '-' in my_input:\r\n",
    "        a=float(my_input[:my_input.index('-')])\r\n",
    "        b=float(my_input[my_input.index('-')+1:])\r\n",
    "        return (a+b)/2\r\n",
    "    else:\r\n",
    "        return my_input\r\n",
    "\r\n",
    "def pH_SD_fxn(same_input,original):\r\n",
    "    if 'as' in same_input:\r\n",
    "        same_input=same_input[:-7]\r\n",
    "    if ')' in same_input:\r\n",
    "        return float(same_input[same_input.index(')')+1:])\r\n",
    "    elif '-' in same_input:\r\n",
    "        a=float(same_input[:same_input.index('-')])\r\n",
    "        b=float(same_input[same_input.index('-')+1:])\r\n",
    "        return (b-a)/2\r\n",
    "    else:\r\n",
    "        return original\r\n",
    "df5['pH_SD']=df5.apply(lambda row: pH_SD_fxn(row['pH'],row['pH_SD']),axis=1)\r\n",
    "df5['pH']=df5.apply(lambda row: pH_fxn(row['pH']),axis=1)\r\n",
    "#df5.to_csv('df5.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "#Rename Sorbent concentration info and export csv of all concentration data\r\n",
    "def sorbent_SD_fxn(my_input):\r\n",
    "    if '<' in my_input:\r\n",
    "        return float(my_input[1:])\r\n",
    "    elif '(1.2-1.3)' in my_input:\r\n",
    "        return 0.05*10**(-7)\r\n",
    "    elif ' - ' in my_input:\r\n",
    "        a=float(my_input[:my_input.index(' - ')])\r\n",
    "        b=float(my_input[my_input.index(' - ')+3:])\r\n",
    "        return (b-a)/2\r\n",
    "    else:\r\n",
    "        return my_input\r\n",
    "\r\n",
    "def sorbent_fxn(same_input):\r\n",
    "    if '<' in same_input:\r\n",
    "        return float(same_input[1:])\r\n",
    "    elif '(1.2-1.3)' in same_input:\r\n",
    "        return 1.25*10**(-7)\r\n",
    "    elif ' - ' in same_input:\r\n",
    "        a=float(same_input[:same_input.index(' - ')])\r\n",
    "        b=float(same_input[same_input.index(' - ')+3:])\r\n",
    "        return (a+b)/2\r\n",
    "    elif 'and' in same_input:\r\n",
    "        return 'NA'\r\n",
    "    else:\r\n",
    "        return same_input\r\n",
    "\r\n",
    "df5.rename({'C init(mol/L)':'Sorbent_val'},axis=1,inplace=True)\r\n",
    "df5['Sorbent_SD']='NA'\r\n",
    "df5['Sorbent_SD']=df5.apply(lambda row: sorbent_SD_fxn(row['Sorbent_val']),axis=1)\r\n",
    "df5['Sorbent_val']=df5.apply(lambda row: sorbent_fxn(row['Sorbent_val']),axis=1)\r\n",
    "df5['Sorbent_units']='mol/L'\r\n",
    "#df5.to_csv('df5.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "#Remove columns\r\n",
    "df5.drop('Contact time(day)', inplace=True, axis=1)\r\n",
    "df5.drop('Separation', inplace=True, axis=1)\r\n",
    "df5.drop('Eh init(mV)', inplace=True, axis=1)\r\n",
    "df5.drop('Eh end(mV)', inplace=True, axis=1)\r\n",
    "#df5.to_csv('df5.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "#Multistep conversion of gas composition info\r\n",
    "df6 = pd.read_csv(path_1.joinpath(\"gas_composition_conversion.txt\"),sep = '\\t')\r\n",
    "df6 = df6.reset_index().set_index('jaea: atm/redox condition')\r\n",
    "other_reference=['Gas1','Gas1_val','Gas1_SD','Gas1_units','Gas2','Gas2_val','Gas2_SD','Gas2_units','Gas3','Gas3_val','Gas3_SD','Gas3_units']\r\n",
    "df5.fillna('NA',inplace=True)\r\n",
    "for g in other_reference:\r\n",
    "    df5[g]=df5.apply(lambda row: df6.loc[row['atm/redox condition'],g] if row['atm/redox condition'] != 'NA' else 'NA',axis=1)\r\n",
    "#df5.to_csv('df5.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "#Remove columns\r\n",
    "df5.drop('Note', inplace=True, axis=1)\r\n",
    "df5.drop('replicates, n', inplace=True, axis=1)\r\n",
    "df5.drop('additional/information', inplace=True, axis=1)\r\n",
    "df5.drop('Kd Graph Data', inplace=True, axis=1)\r\n",
    "df5.drop('Temp Graph Data', inplace=True, axis=1)\r\n",
    "df5.drop('pH Graph Data', inplace=True, axis=1)\r\n",
    "df5.drop('Time Graph Data', inplace=True, axis=1)\r\n",
    "df5.drop('Eh Graph Data', inplace=True, axis=1)\r\n",
    "df5.drop('Cinit Graph Data', inplace=True, axis=1)\r\n",
    "df5.drop('Solution/Solid Graph Data', inplace=True, axis=1)\r\n",
    "df5.drop('Data type', inplace=True, axis=1)\r\n",
    "#df5.to_csv('df5.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "#Multistep conversion of jaea: kd column\r\n",
    "def last_fxn(my_input):\r\n",
    "    a=float(my_input[:my_input.index(' - ')])\r\n",
    "    b=float(my_input[my_input.index(' - ')+3:])\r\n",
    "    return (a+b)/2\r\n",
    "\r\n",
    "df5['check']=df5.apply(lambda row: True if ('>' in row['Kd(m3/kg)'] or '<' in row['Kd(m3/kg)']) else False,axis=1)\r\n",
    "df5['Kd(m3/kg)']=df5.apply(lambda row: float(row['Kd(m3/kg)'][1:]) if row['check'] is True else row['Kd(m3/kg)'],axis=1)\r\n",
    "df5['Kd(m3/kg)']=df5.apply(lambda row: last_fxn(row['Kd(m3/kg)']) if ' - ' in str(row['Kd(m3/kg)']) else row['Kd(m3/kg)'],axis=1)\r\n",
    "df5['error'].replace({'?}0.2log':0.2, '0.5log':0.5, '-':'NA'},inplace=True)\r\n",
    "df5['error']= df5.apply(lambda row: 0.05*float(row['Kd(m3/kg)']) if (row['error']=='?`5%' or row['error']=='5%') else row['error'],axis=1)\r\n",
    "df5['Aq_val'] = df5.apply(lambda row: float(row['Sorbent_val']) / (float(row['Kd(m3/kg)']) * float(row['Mineral_val']) + 1) if ((row['Sorbent_val']) != 'NA' and (row['Kd(m3/kg)']) != 'NA' and (row['Mineral_val']) != 'NA') else 'NA',axis=1)\r\n",
    "df5['Aq_SD'] = df5.apply(lambda row: ((float(row['Sorbent_val']) / (float(row['Kd(m3/kg)']) * float(row['Sorbent_val']) + 1)) - (float(row['Sorbent_val']) / ((float(row['Kd(m3/kg)']) + float(row['error'])) * float(row['Sorbent_val']) +1))) if ((row['Sorbent_val']) != 'NA' and (row['Kd(m3/kg)']) != 'NA' and (row['Mineral_val']) != 'NA' and row['error'] != 'NA' and row['check'] is False) else (row['Kd(m3/kg)'] if row['check'] is True else 'NA'),axis=1)\r\n",
    "df5['Aq_units']='mol/L'\r\n",
    "df5['Sorbed_val']=df5.apply(lambda row: float(row['Sorbent_val'])-float(row['Aq_val']) if ((row['Sorbent_val']) != 'NA' and (row['Aq_val']) != 'NA') else 'NA',axis=1)\r\n",
    "df5['Sorbed_SD']=df5.apply(lambda row: math.sqrt((float(row['Sorbent_SD'])*float(row['Sorbent_SD']))+(float(row['Aq_SD'])*float(row['Aq_SD']))) if ((row['Sorbent_SD']) != 'NA' and (row['Aq_SD']) != 'NA') else 'NA',axis=1)\r\n",
    "df5['Sorbed_units']='mol/L'\r\n",
    "df5.drop('Kd(m3/kg)', inplace=True, axis=1)\r\n",
    "df5.drop('error', inplace=True, axis=1)\r\n",
    "df5.drop('check', inplace=True, axis=1)\r\n",
    "df5.to_csv('df5.csv')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "interpreter": {
   "hash": "6998a965c5b10159c297ab78fc148a44ad705a861c4aea761fe0a581ce3b1e65"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}